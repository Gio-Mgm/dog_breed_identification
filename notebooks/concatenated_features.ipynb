{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n* The Notebook is created on Dog Breed Dataset.\n* As there are 120 Different Breeds of Dog present in the Dataset it becomes difficult for a single pretrained model to give Good results.\n* Here we used 3 different pretrained models to extract features from the images and combined them and then trained a DNN model on these features.","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:22:10.199706Z","iopub.execute_input":"2021-06-11T12:22:10.200083Z","iopub.status.idle":"2021-06-11T12:22:11.262114Z","shell.execute_reply.started":"2021-06-11T12:22:10.200046Z","shell.execute_reply":"2021-06-11T12:22:11.261197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setting train and test directories","metadata":{}},{"cell_type":"code","source":"train_dir = '../input/dog-breed-identification/train'\ntest_dir = '../input/dog-breed-identification/test'\n\ntrain_size = len(os.listdir('../input/dog-breed-identification/train'))\ntest_size = len(os.listdir('../input/dog-breed-identification/test'))\n\ntrain_size,test_size","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:22:11.264868Z","iopub.execute_input":"2021-06-11T12:22:11.265247Z","iopub.status.idle":"2021-06-11T12:22:11.269935Z","shell.execute_reply.started":"2021-06-11T12:22:11.265211Z","shell.execute_reply":"2021-06-11T12:22:11.268732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/dog-breed-identification/labels.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:22:11.703294Z","iopub.execute_input":"2021-06-11T12:22:11.703833Z","iopub.status.idle":"2021-06-11T12:22:11.758411Z","shell.execute_reply.started":"2021-06-11T12:22:11.703785Z","shell.execute_reply":"2021-06-11T12:22:11.757307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extracting different classes\ndog_breeds = sorted(df['breed'].unique())\nn_classes = len(dog_breeds)\nprint(n_classes)\ndog_breeds","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:22:11.76293Z","iopub.execute_input":"2021-06-11T12:22:11.763279Z","iopub.status.idle":"2021-06-11T12:22:11.778372Z","shell.execute_reply.started":"2021-06-11T12:22:11.763245Z","shell.execute_reply":"2021-06-11T12:22:11.77663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Converting classes to numbers\nclass_to_num = dict(zip(dog_breeds,range(n_classes)))\nclass_to_idx = {x:i for i,x in enumerate(class_df.breed.unique())}\nidx_to_class = {i:x for i,x in enumerate(class_df.breed.unique())}","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:22:11.780863Z","iopub.execute_input":"2021-06-11T12:22:11.781165Z","iopub.status.idle":"2021-06-11T12:22:11.78639Z","shell.execute_reply.started":"2021-06-11T12:22:11.781136Z","shell.execute_reply":"2021-06-11T12:22:11.785326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to load and convert images to array\nfrom keras.preprocessing.image import load_img\nfrom keras.utils import to_categorical\n\ndef images_to_array(data_dir,df,image_size):\n    image_names = df['id']\n    image_labels = df['breed']\n    data_size = len(image_names)\n    \n    X = np.zeros([data_size,image_size[0],image_size[1],image_size[2]],dtype = np.uint8)\n    y = np.zeros([data_size,1],dtype = np.uint8)\n    \n    for i in range(data_size):\n        img_name = image_names[i]\n        img_dir = os.path.join(data_dir,img_name+'.jpg')\n        img_pixels = load_img(img_dir,target_size=image_size)\n        X[i] = img_pixels\n        y[i] = class_to_num[image_labels[i]]\n        \n    y = to_categorical(y)\n    \n    ind = np.random.permutation(data_size)\n    X = X[ind]\n    y = y[ind]\n    print('Ouptut Data Size: ', X.shape)\n    print('Ouptut Label Size: ', y.shape)\n    return X, y     ","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:22:11.7877Z","iopub.execute_input":"2021-06-11T12:22:11.788054Z","iopub.status.idle":"2021-06-11T12:22:18.461592Z","shell.execute_reply.started":"2021-06-11T12:22:11.788022Z","shell.execute_reply":"2021-06-11T12:22:18.460463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Selecting image size according to pretrained models\nimg_size = (299,299,3)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:22:18.46284Z","iopub.execute_input":"2021-06-11T12:22:18.463123Z","iopub.status.idle":"2021-06-11T12:22:18.467102Z","shell.execute_reply.started":"2021-06-11T12:22:18.463096Z","shell.execute_reply":"2021-06-11T12:22:18.466413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = images_to_array(train_dir,df,img_size)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:22:18.468292Z","iopub.execute_input":"2021-06-11T12:22:18.468694Z","iopub.status.idle":"2021-06-11T12:24:00.392498Z","shell.execute_reply.started":"2021-06-11T12:22:18.468664Z","shell.execute_reply":"2021-06-11T12:24:00.391252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extracting Features","metadata":{}},{"cell_type":"code","source":"#Function to extract features from images\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D,Lambda, Dropout, InputLayer, Input\n\ndef get_features(model_name, data_preprocessor, input_size, data):\n    #Prepare pipeline.\n    input_layer = Input(input_size)\n    preprocessor = Lambda(data_preprocessor)(input_layer)\n    base_model = model_name(weights='imagenet', include_top=False,\n                            input_shape=input_size)(preprocessor)\n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, batch_size=32, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:24:00.395324Z","iopub.execute_input":"2021-06-11T12:24:00.395696Z","iopub.status.idle":"2021-06-11T12:24:00.40452Z","shell.execute_reply.started":"2021-06-11T12:24:00.395662Z","shell.execute_reply":"2021-06-11T12:24:00.40342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extracting features using InceptionV3\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\ninception_preprocessor = preprocess_input\ninception_features = get_features(InceptionV3,\n                                  inception_preprocessor,\n                                  img_size, X)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:24:00.406027Z","iopub.execute_input":"2021-06-11T12:24:00.40647Z","iopub.status.idle":"2021-06-11T12:42:51.245705Z","shell.execute_reply.started":"2021-06-11T12:24:00.406427Z","shell.execute_reply":"2021-06-11T12:42:51.244346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extracting features using Xception\nfrom keras.applications.xception import Xception, preprocess_input\nxception_preprocessor = preprocess_input\nxception_features = get_features(Xception,\n                                 xception_preprocessor,\n                                 img_size, X)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T12:42:51.248511Z","iopub.execute_input":"2021-06-11T12:42:51.248894Z","iopub.status.idle":"2021-06-11T13:19:48.628938Z","shell.execute_reply.started":"2021-06-11T12:42:51.248854Z","shell.execute_reply":"2021-06-11T13:19:48.627511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extracting features using InceptionResnetV2\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\ninc_resnet_preprocessor = preprocess_input\ninc_resnet_features = get_features(InceptionResNetV2,\n                                   inc_resnet_preprocessor,\n                                   img_size, X)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T13:19:48.631029Z","iopub.execute_input":"2021-06-11T13:19:48.631406Z","iopub.status.idle":"2021-06-11T14:01:45.358076Z","shell.execute_reply.started":"2021-06-11T13:19:48.631369Z","shell.execute_reply":"2021-06-11T14:01:45.356827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Contatenating features","metadata":{}},{"cell_type":"code","source":"\nfinal_features = np.concatenate([inception_features,\n                                 xception_features,\n                                 inc_resnet_features,], axis=-1)\nprint('Final feature maps shape', final_features.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:01:45.360275Z","iopub.execute_input":"2021-06-11T14:01:45.360636Z","iopub.status.idle":"2021-06-11T14:01:45.645371Z","shell.execute_reply.started":"2021-06-11T14:01:45.3606Z","shell.execute_reply":"2021-06-11T14:01:45.643943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:01:45.647226Z","iopub.execute_input":"2021-06-11T14:01:45.647663Z","iopub.status.idle":"2021-06-11T14:01:45.663297Z","shell.execute_reply.started":"2021-06-11T14:01:45.647611Z","shell.execute_reply":"2021-06-11T14:01:45.662299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building and training Model","metadata":{}},{"cell_type":"code","source":"#Callbacks\nfrom keras.callbacks import EarlyStopping\nEarlyStop_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:01:45.665335Z","iopub.execute_input":"2021-06-11T14:01:45.665659Z","iopub.status.idle":"2021-06-11T14:01:45.680425Z","shell.execute_reply.started":"2021-06-11T14:01:45.665628Z","shell.execute_reply":"2021-06-11T14:01:45.678977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building Model\nfrom keras.models import Sequential\nmodel = Sequential()\nmodel.add(InputLayer(final_features.shape[1:]))\nmodel.add(Dropout(0.7))\nmodel.add(Dense(120,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:01:45.682636Z","iopub.execute_input":"2021-06-11T14:01:45.682958Z","iopub.status.idle":"2021-06-11T14:01:45.748336Z","shell.execute_reply.started":"2021-06-11T14:01:45.682928Z","shell.execute_reply":"2021-06-11T14:01:45.747077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compiling Model\nmodel.compile(optimizer='adam',\n            loss='categorical_crossentropy',\n            metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:01:45.749922Z","iopub.execute_input":"2021-06-11T14:01:45.750475Z","iopub.status.idle":"2021-06-11T14:01:45.768574Z","shell.execute_reply.started":"2021-06-11T14:01:45.750424Z","shell.execute_reply":"2021-06-11T14:01:45.767552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training Model\nhistory = model.fit(final_features,\n                  y,\n                  batch_size=32,\n                  epochs=50,\n                  validation_split=0.1,\n                  callbacks=my_callback)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:01:45.769769Z","iopub.execute_input":"2021-06-11T14:01:45.770429Z","iopub.status.idle":"2021-06-11T14:02:05.569362Z","shell.execute_reply.started":"2021-06-11T14:01:45.77039Z","shell.execute_reply":"2021-06-11T14:02:05.568094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading and Predicting test Images","metadata":{}},{"cell_type":"code","source":"#Converting test images to array\ndef images_to_array2(data_dir,df, img_size):\n    '''\n    Do same as images_to_array but omit some unnecessary steps for test data.\n    '''\n    images_names = df['id']\n    data_size = len(images_names)\n    X = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n    \n    for i in range(data_size):\n        image_name = images_names[i]\n        img_dir = os.path.join(data_dir, image_name+'.jpg')\n        img_pixels = load_img(img_dir, target_size=img_size)\n        X[i] = img_pixels\n        \n    print('Ouptut Data Size: ', X.shape)\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:02:05.57082Z","iopub.execute_input":"2021-06-11T14:02:05.571126Z","iopub.status.idle":"2021-06-11T14:02:05.580025Z","shell.execute_reply.started":"2021-06-11T14:02:05.571095Z","shell.execute_reply":"2021-06-11T14:02:05.578553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = pd.read_csv('../input/dog-breed-identification/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:02:05.582059Z","iopub.execute_input":"2021-06-11T14:02:05.582569Z","iopub.status.idle":"2021-06-11T14:02:06.187679Z","shell.execute_reply.started":"2021-06-11T14:02:05.582521Z","shell.execute_reply":"2021-06-11T14:02:06.18665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = images_to_array2(test_dir, sample_df, img_size)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:02:06.190298Z","iopub.execute_input":"2021-06-11T14:02:06.191064Z","iopub.status.idle":"2021-06-11T14:03:56.182126Z","shell.execute_reply.started":"2021-06-11T14:02:06.191012Z","shell.execute_reply":"2021-06-11T14:03:56.180866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extract test data features.\ninception_features = get_features(InceptionV3, inception_preprocessor, img_size, test_data)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:03:56.183817Z","iopub.execute_input":"2021-06-11T14:03:56.184187Z","iopub.status.idle":"2021-06-11T14:22:32.870528Z","shell.execute_reply.started":"2021-06-11T14:03:56.18414Z","shell.execute_reply":"2021-06-11T14:22:32.869505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xception_features = get_features(Xception, xception_preprocessor, img_size, test_data)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:22:32.8721Z","iopub.execute_input":"2021-06-11T14:22:32.872432Z","iopub.status.idle":"2021-06-11T14:58:25.708695Z","shell.execute_reply.started":"2021-06-11T14:22:32.872401Z","shell.execute_reply":"2021-06-11T14:58:25.707626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, test_data)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:58:25.710739Z","iopub.execute_input":"2021-06-11T14:58:25.711161Z","iopub.status.idle":"2021-06-11T15:40:39.360185Z","shell.execute_reply.started":"2021-06-11T14:58:25.711118Z","shell.execute_reply":"2021-06-11T15:40:39.358868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features = np.concatenate([inception_features,\n                                 xception_features,\n                                 inc_resnet_features],axis=-1)\nprint('Final feature maps shape', test_features.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:40:39.361868Z","iopub.execute_input":"2021-06-11T15:40:39.362222Z","iopub.status.idle":"2021-06-11T15:40:39.61542Z","shell.execute_reply.started":"2021-06-11T15:40:39.362163Z","shell.execute_reply":"2021-06-11T15:40:39.61442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test_data","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:40:39.616814Z","iopub.execute_input":"2021-06-11T15:40:39.617089Z","iopub.status.idle":"2021-06-11T15:40:39.740143Z","shell.execute_reply.started":"2021-06-11T15:40:39.61706Z","shell.execute_reply":"2021-06-11T15:40:39.739297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(test_features, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:40:39.741484Z","iopub.execute_input":"2021-06-11T15:40:39.74194Z","iopub.status.idle":"2021-06-11T15:40:40.740435Z","shell.execute_reply.started":"2021-06-11T15:40:39.7419Z","shell.execute_reply":"2021-06-11T15:40:40.73941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for breed in dog_breeds:\n    sample_df[breed] = y_pred[:,class_to_num[breed]]\nsample_df.to_csv('pred.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:40:40.742526Z","iopub.execute_input":"2021-06-11T15:40:40.743008Z","iopub.status.idle":"2021-06-11T15:40:43.903713Z","shell.execute_reply.started":"2021-06-11T15:40:40.742959Z","shell.execute_reply":"2021-06-11T15:40:43.9024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:40:43.905245Z","iopub.execute_input":"2021-06-11T15:40:43.905566Z","iopub.status.idle":"2021-06-11T15:40:43.945402Z","shell.execute_reply.started":"2021-06-11T15:40:43.905535Z","shell.execute_reply":"2021-06-11T15:40:43.944128Z"},"trusted":true},"execution_count":null,"outputs":[]}]}